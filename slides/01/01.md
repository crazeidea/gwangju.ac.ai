---
marp: true
---

![bg left:40%](https://www.einfochips.com/blog/wp-content/uploads/2019/04/3-ways-ai-chatbots-can-transform-the-telecom-industry-featured.jpg)
# **대형 언어 모델을 활용한 대화 시스템의 최근 동향**
### 뉴미디어특강
### 2023468101 최강훈
---
# 챗봇의 분류
### 오픈 도메인 대화 시스템 (Open-Domain Dialogue System, ODD)
- 심심이, 이루다
### 목적 지향형 대화 시스템 (Task-Oriented Dialogue System, TOD)
-  삼성 Bixby, Google Assistant, Apple Siri, Amazon Alexa
---
## 오픈 도메인 대화 시스템 (Open-Domain Dialogue System, ODD)
### 1. DialoGPT (Microsoft)
- 2019년 공개된 GPT-2의 구조와 학습 방법론을 기반으로 제작된 **최초의 공개된** 대형 사전 학습 대화 시스템.
- 1.5억건의 Reddit 스레드 데이터를 Single-Turn<sup>[1]</sup> 방식으로 학습.
- large (762M) / medium (345M) / small (117M) 모델을 오픈소스로 공개.
<!-- _footer : '[1] 발화 - 답변으로 구성된 방식'-->

---

### 2. GODEL (Microsoft)
- 2022년 5월에 공개.
- MS-MACRO, UnifiedQA 등의 질의 응답 데이터와 DSTC7-Task-2, Schema-Guided Dialogue 등의 TOD 데이터 학습.

---
### 3.  Meena (Google)
- 2.6B (341GB)의 데이터 학습.
- Evolved Transformer <sup>[2]</sup>
- Sensibleness and Specificity Average 수동적 평가 방법론 제안.
  - "대화가 문맥상 말이 되는가?" / "대화가 구체적인가?"
  - 인간 (86%)에 가장 근접한 (79%) 평가. <sup>[3]</sup>
  - Perplexity<sup>[4]</sup> 와의 높은 상관관계.

<!--  _footer : '[2] 모델의 신경망 아키텍쳐를 유전 알고리즘을 기반으로 탐색하는 Transformer </br> [3] https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html </br> [4] 다음 생성될 단어의 예측 정도'-->
---
### 4. LamDA (Google)
- 137B의 데이터 학습.
- 안정성과 근거성 증대.
  - 크라우드 소싱을 통한 대화 데이터 수집 및 학습.
---
### 5. BlenderBot (Meta)
- 9.4B의 데이터 학습
- Meta의 ODD 관련 연구 성과를 결합.
    - Blended Skill Talk = Empathetic Dialogues + Persona Chat + Wizard of Wikipedia
### 6. BlenderBot2 (Meta)
- 인터넷 검색 모듈 추가.
- 이전 모델과 같은 크기의 모델이지만 더 높은 성능 평가.
---
### 7. BlenderBot3 (Meta)
- Continual Learning
    - Human-in-Loop : 사용자의 직접적인 피드벡을 모델에 반영
- 모델, 코드, 배포 방법론, UI 디자인까지 모두 공개.
<br />
>대화에 특화되지 않은 모델이라도, GPT-3 (175B)와 유사한 크기의 모델은 특화된 학습이 없어도 대화가 일정 수준 가능.
---
![](https://d3i71xaburhd42.cloudfront.net/77440e3a9666bfc69b9947f75797a002024e8cd8/5-Figure1-1.png)
---
---
## 목적 지향형 대화 시스템 (Task-Oriented Dialogue Systems, TOD)
![TOD](https://github.com/yukyunglee/Awesome-Dialogue-State-Tracking/raw/6d1a4f5bd2dc619c8dac08138182c92bb900730d/Img/%231.png)
---
---
## 목적 지향형 대화 시스템 (Task-Oriented Dialogue Systems, TOD)
1. Natural Language Understanding (NLU) : 자연어 표현에서의 의미와 패턴을 추론
2. Dialogue State Tracking (DST) : 현재 대화의 상태를 추적
3. Dialogue Policy (DP) : 과거 대화 상태를 기반으로 시스템의 행동을 예측.
4. Natural Language Generation (NLG) : 시스템의 계산 결과를 자연어로 출력
### TOD 개발의 어려움
1. 데이터 확보의 어려움과 높은 비용.
2. 외부 데이터의 필요로 인한 사전 학습의 한계.
---
### 대화 상태 추적 (Dialogue State Tracking)
- 사용자의 목표/의도, 목표/의도 달성의 제한 사항, 요구사항을 파악.
- 미리 설정된 Slot의 Value을 추론.

### 분류 기반 모델에서 생성 기반 모델
1. LLM에 내장되어 있는 지식을 이용.
    - Slot과 Value를 자연어로써 전달.
    - 생성 기반 모델의 학습 데이터 도메인의 일치 필요.
2. Question Answering
    - 직접적으로 질문 하는 방식.
3. 질의 응답이 아닌 '대화 요약'

> 실제 사용 가능한 수준에는 부족한 것으로 평가.
---
### 종단간 목적 지향형 대화 시스템 (End-to-End Task-Oriented Dialogue Systems)
- 파이프라인 없이 하나의 모델이 한 번의 계산으로 대화를 끝까지 생성.
- LLM의 학습 방법론을 기반으로 모델 학습.
--- 
# 결론
## ODD
- 풍부한 데이터를 기반으로 LLM의 학습 방식을 기반으로 한 대형 대화 모델 개발 방향.
## TOD
- LLM을 직접 사용하여 한계 개선 및 효과 증대.